{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc3eecc3-1def-4723-8bee-060429cc69ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+------+------------+--------------+-----------+------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n|Customer_ID|Age|Gender|  Occupation|Marital Status|Family Size|Income|Expenditure|Use Frequency|Loan Category|Loan Amount|Overdue| Debt Record| Returned Cheque| Dishonour of Bill|\n+-----------+---+------+------------+--------------+-----------+------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n|    IB14001| 30|  MALE|BANK MANAGER|        SINGLE|          4| 50000|      22199|            6|      HOUSING| 10,00,000 |      5|      42,898|               6|                 9|\n|    IB14008| 44|  MALE|   PROFESSOR|       MARRIED|          6| 51000|      19999|            4|     SHOPPING|     50,000|      3|      33,999|               1|                 5|\n|    IB14012| 30|FEMALE|     DENTIST|        SINGLE|          3| 58450|      27675|            5|   TRAVELLING|     75,000|      6|      20,876|               3|                 1|\n|    IB14018| 29|  MALE|     TEACHER|       MARRIED|          5| 45767|      12787|            3|    GOLD LOAN|  6,00,000 |      7|      11,000|               0|                 4|\n|    IB14022| 34|  MALE|      POLICE|        SINGLE|          4| 43521|      11999|            3|   AUTOMOBILE|  2,00,000 |      2|      43,898|               1|                 2|\n+-----------+---+------+------------+--------------+-----------+------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initializing SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Loan Data Processing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# File path\n",
    "file_path = \"/FileStore/tables/loan-1.csv\"\n",
    "\n",
    "# Load the CSV file into a PySpark DataFrame\n",
    "loans_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "loans_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9429159-a85e-40e2-a819-6333f781028c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n|     loan category|count|\n+------------------+-----+\n|           HOUSING|   67|\n|        TRAVELLING|   53|\n|       BOOK STORES|    7|\n|       AGRICULTURE|   12|\n|         GOLD LOAN|   77|\n|  EDUCATIONAL LOAN|   20|\n|        AUTOMOBILE|   60|\n|          BUSINESS|   24|\n|COMPUTER SOFTWARES|   35|\n|           DINNING|   14|\n|          SHOPPING|   35|\n|       RESTAURANTS|   41|\n|       ELECTRONICS|   14|\n|          BUILDING|    7|\n|        RESTAURANT|   20|\n|   HOME APPLIANCES|   14|\n+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "loans_per_category = loans_df.groupBy(\"loan category\").count()\n",
    "\n",
    "loans_per_category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2179502-d59a-418e-9364-a2ca8eab9417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people who have taken loans greater than 1 Lakh: 449\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "# Clean and convert \"Loan Amount\" to integer\n",
    "loans_df = loans_df.withColumn(\n",
    "    \"Loan Amount\", \n",
    "    regexp_replace(col(\"Loan Amount\"), \"[^0-9]\", \"\").cast(\"int\")\n",
    ")\n",
    "\n",
    "\n",
    "# Filter loans greater than 1 Lakh (1,00,000)\n",
    "high_value_loans = loans_df.filter(loans_df[\"Loan Amount\"] > 100000)\n",
    "\n",
    "# Count the number of unique customers\n",
    "num_people_high_loans = high_value_loans.select(\"Customer_ID\").distinct().count()\n",
    "\n",
    "print(f\"Number of people who have taken loans greater than 1 Lakh: {num_people_high_loans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d82f0e0-8c2a-4d3c-988f-3e8cdd083bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with Income greater than 60,000: 198\n"
     ]
    }
   ],
   "source": [
    "#people with Income greater than 60,000\n",
    "high_income_people = loans_df.filter(loans_df[\"Income\"] > 60000)\n",
    "\n",
    "# Count the number of unique customers\n",
    "num_high_income_people = high_income_people.select(\"Customer_ID\").distinct().count()\n",
    "\n",
    "print(f\"Number of people with Income greater than 60,000: {num_high_income_people}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3e949e-c4f8-4470-8737-8b0ee11fcca0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|num_people|\n+----------+\n|       198|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Create a temporary view for SQL queries\n",
    "loans_df.createOrReplaceTempView(\"loans\")\n",
    "\n",
    "result_3 = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT Customer_ID) AS num_people\n",
    "    FROM loans\n",
    "    WHERE Income > 60000\n",
    "\"\"\")\n",
    "result_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86325ac-9cf4-4e6f-9a6e-6bf03b55977c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with 2 or more returned cheques and income less than 50,000: 136\n"
     ]
    }
   ],
   "source": [
    "#people with 2 or more returned cheques and income less than 50,000\n",
    "result_4 = loans_df.filter((loans_df[\" Returned Cheque\"] >= 2) & \n",
    "                           (loans_df[\"Income\"] < 50000))\n",
    "\n",
    "# Count the number of unique customers\n",
    "num_people_4 = result_4.select(\"Customer_ID\").distinct().count()\n",
    "\n",
    "print(f\"Number of people with 2 or more returned cheques and income less than 50,000: {num_people_4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bb78d8-b3a9-48d2-bd6f-23e38de1cea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|num_people|\n+----------+\n|       136|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "result_4 = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT Customer_ID) AS num_people\n",
    "    FROM loans\n",
    "    WHERE ` Returned Cheque` >= 2 AND Income < 50000\n",
    "\"\"\")\n",
    "result_4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4183b96-6930-45d5-94ab-2db09764e4d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensure the DataFrame has no problematic column names\n",
    "loans_df = loans_df.withColumnRenamed(\" Returned Cheque\", \"Returned Cheque\") \\\n",
    "                   .withColumnRenamed(\"Marital Status\", \"Marital_Status\")\n",
    "\n",
    "# Create a temporary view for SQL queries\n",
    "loans_df.createOrReplaceTempView(\"loans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "631a4d39-250a-47f3-89e7-306877315205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with 2 or more returned cheques and are single: 111\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "# Normalize the `Marital_Status` column to lowercase for consistent comparison\n",
    "loans_df = loans_df.withColumn(\"Marital_Status\", lower(loans_df[\"Marital_Status\"]))\n",
    "\n",
    "result_5 = loans_df.filter((loans_df[\"Returned Cheque\"] >= 2) & \n",
    "                           (loans_df[\"Marital_Status\"] == \"single\"))\n",
    "\n",
    "num_people_5 = result_5.select(\"Customer_ID\").distinct().count()\n",
    "\n",
    "print(f\"Number of people with 2 or more returned cheques and are single: {num_people_5}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97390a65-684b-40c0-a932-19b74bb99217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|num_people|\n+----------+\n|       111|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "result_5 = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT Customer_ID) AS num_people\n",
    "    FROM loans\n",
    "    WHERE `Returned Cheque` >= 2 AND LOWER(Marital_Status) = 'single'\n",
    "\"\"\")\n",
    "result_5.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e96245a-b2fe-415c-ba8a-d05cdcc9fe2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|num_people|\n+----------+\n|         6|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#find the number of people with expenditure > 50,000\n",
    "result_6_sql = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT Customer_ID) AS num_people\n",
    "    FROM loans\n",
    "    WHERE Expenditure > 50000\n",
    "\"\"\")\n",
    "result_6_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f7754f-3a7a-4cd4-a619-f9c7b34c543f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with expenditure over 50,000: 6\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for expenditure > 50,000\n",
    "result_6_df = loans_df.filter(loans_df[\"Expenditure\"] > 50000)\n",
    "\n",
    "# Count distinct Customer_ID\n",
    "num_people_6 = result_6_df.select(\"Customer_ID\").distinct().count()\n",
    "\n",
    "print(f\"Number of people with expenditure over 50,000: {num_people_6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c365f62f-0933-41f7-affd-c096b21906c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|num_people|\n+----------+\n|        62|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "result_7_sql = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT Customer_ID) AS num_people\n",
    "    FROM loans\n",
    "    WHERE Income > 30000 AND Overdue = 1\n",
    "\"\"\")\n",
    "result_7_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e862f2a-81e6-4157-bca9-bda1628c2cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of members eligible for credit cards: 62\n"
     ]
    }
   ],
   "source": [
    "result_7_df = loans_df.filter((loans_df[\"Income\"] > 30000) & \n",
    "                              (loans_df[\"Overdue\"] == 1))\n",
    "\n",
    "num_people_7 = result_7_df.select(\"Customer_ID\").distinct().count()\n",
    "\n",
    "print(f\"Number of members eligible for credit cards: {num_people_7}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "loandata",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
