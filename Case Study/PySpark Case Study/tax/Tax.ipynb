{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c466c0f4-a9ca-4100-9c52-ee21666e8322",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+----------------+-------------+-----------+\n|   Account No| TRANSACTION DETAILS|VALUE DATE| WITHDRAWAL AMT | DEPOSIT AMT |BALANCE AMT|\n+-------------+--------------------+----------+----------------+-------------+-----------+\n|409000611074'|TRF FROM  Indiafo...| 29-Jun-17|            NULL|    1000000.0|  1000000.0|\n|409000611074'|TRF FROM  Indiafo...|  5-Jul-17|            NULL|    1000000.0|  2000000.0|\n|409000611074'|FDRL/INTERNAL FUN...| 18-Jul-17|            NULL|     500000.0|  2500000.0|\n|409000611074'|TRF FRM  Indiafor...|  1-Aug-17|            NULL|    3000000.0|  5500000.0|\n|409000611074'|FDRL/INTERNAL FUN...| 16-Aug-17|            NULL|     500000.0|  6000000.0|\n+-------------+--------------------+----------+----------------+-------------+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initializing SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Loan Data Processing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# File path\n",
    "file_path = \"/FileStore/tables/txn.csv\"\n",
    "\n",
    "# Load the CSV file into a PySpark DataFrame\n",
    "loans_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "loans_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c56ab7-7481-4f53-83f9-b21c931e8137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum withdrawal amount: 459447546.4\n"
     ]
    }
   ],
   "source": [
    "# Finding the maximum withdrawal amount\n",
    "max_withdrawal = loans_df.agg({\" WITHDRAWAL AMT \": \"max\"}).collect()[0][0]\n",
    "\n",
    "print(f\"Maximum withdrawal amount: {max_withdrawal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33c10451-dd96-4a10-ab31-e506613e8805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n|Max_Withdrawal|\n+--------------+\n|  459447546.40|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "max_withdrawal_sql = spark.sql(\"\"\"\n",
    "    SELECT CAST(MAX(` WITHDRAWAL AMT `) AS DECIMAL(20, 2)) AS Max_Withdrawal\n",
    "    FROM transactions\n",
    "\"\"\")\n",
    "max_withdrawal_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd5cc3a-7f8c-4fb1-a282-029212313f08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|   Account No|Min_Withdrawal|\n+-------------+--------------+\n|409000438611'|           0.2|\n|     1196711'|          0.25|\n|     1196428'|          0.25|\n|409000493210'|          0.01|\n|409000611074'|         120.0|\n|409000425051'|          1.25|\n|409000405747'|          21.0|\n|409000493201'|           2.1|\n|409000438620'|          0.34|\n|409000362497'|          0.97|\n+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "min_withdrawal_per_account = loans_df.groupBy(\"Account No\").agg({\" WITHDRAWAL AMT \": \"min\"})\n",
    "\n",
    "min_withdrawal_per_account = min_withdrawal_per_account.withColumnRenamed(\"min( WITHDRAWAL AMT )\", \"Min_Withdrawal\")\n",
    "\n",
    "min_withdrawal_per_account.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05b42b7a-9b57-4e3e-926e-492b263f25a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|   Account No|Min_Withdrawal|\n+-------------+--------------+\n|409000438611'|           0.2|\n|     1196711'|          0.25|\n|     1196428'|          0.25|\n|409000493210'|          0.01|\n|409000611074'|         120.0|\n|409000425051'|          1.25|\n|409000405747'|          21.0|\n|409000493201'|           2.1|\n|409000438620'|          0.34|\n|409000362497'|          0.97|\n+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Createing SQL view\n",
    "loans_df.createOrReplaceTempView(\"transactions\")\n",
    "\n",
    "#minimum withdrawal amount for each account\n",
    "min_withdrawal_per_account_sql = spark.sql(\"\"\"\n",
    "    SELECT `Account No`, MIN(` WITHDRAWAL AMT `) AS Min_Withdrawal\n",
    "    FROM transactions\n",
    "    GROUP BY `Account No`\n",
    "\"\"\")\n",
    "min_withdrawal_per_account_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a2720d3-da86-426b-a810-63768ef60e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|   Account No|   Max_Deposit|\n+-------------+--------------+\n|409000438611'|170,250,000.00|\n|     1196711'|500,000,000.00|\n|     1196428'|211,959,442.20|\n|409000493210'| 15,000,000.00|\n|409000611074'|  3,000,000.00|\n|409000425051'| 15,000,000.00|\n|409000405747'|202,100,000.00|\n|409000493201'|  1,000,000.00|\n|409000438620'|544,800,000.00|\n|409000362497'|200,000,000.00|\n+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "# Calculate the maximum deposit per account\n",
    "max_deposit_per_account = loans_df.groupBy(\"Account No\").agg({\" DEPOSIT AMT \": \"max\"})\n",
    "\n",
    "# Rename the column for readability\n",
    "max_deposit_per_account = max_deposit_per_account.withColumnRenamed(\"max( DEPOSIT AMT )\", \"Max_Deposit\")\n",
    "\n",
    "# Format the Max_Deposit column to 2 decimal places\n",
    "max_deposit_per_account = max_deposit_per_account.withColumn(\"Max_Deposit\", format_number(\"Max_Deposit\", 2))\n",
    "    \n",
    "max_deposit_per_account.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28d7d7e9-053c-4906-abcb-90b5e9d1f21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|   Account No|   Max_Deposit|\n+-------------+--------------+\n|409000438611'|170,250,000.00|\n|     1196711'|500,000,000.00|\n|     1196428'|211,959,442.20|\n|409000493210'| 15,000,000.00|\n|409000611074'|  3,000,000.00|\n|409000425051'| 15,000,000.00|\n|409000405747'|202,100,000.00|\n|409000493201'|  1,000,000.00|\n|409000438620'|544,800,000.00|\n|409000362497'|200,000,000.00|\n+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "#find the maximum deposit amount for each account with formatted result\n",
    "max_deposit_per_account_sql = spark.sql(\"\"\"\n",
    "    SELECT `Account No`, \n",
    "           FORMAT_NUMBER(MAX(` DEPOSIT AMT `), 2) AS Max_Deposit\n",
    "    FROM transactions\n",
    "    GROUP BY `Account No`\n",
    "\"\"\")\n",
    "max_deposit_per_account_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bee01c3-2f39-4357-a6f4-e6f203b33ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n|   Account No|       Total_Balance|\n+-------------+--------------------+\n|409000438611'|-2.49486577068339...|\n|     1196711'|-1.60476498101275E13|\n|     1196428'| -8.1418498130721E13|\n|409000493210'|-3.27584952132095...|\n|409000611074'|       1.615533622E9|\n|409000425051'|-3.77211841164998...|\n|409000405747'|-2.43108047067000...|\n|409000493201'|1.0420831829499985E9|\n|409000438620'|-7.12291867951358...|\n|409000362497'| -5.2860004792808E13|\n+-------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "sum_balance_per_account = loans_df.groupBy(\"Account No\").agg({\"BALANCE AMT\": \"sum\"})\n",
    "\n",
    "sum_balance_per_account = sum_balance_per_account.withColumnRenamed(\"sum(BALANCE AMT)\", \"Total_Balance\")\n",
    "\n",
    "sum_balance_per_account.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e28de869-5bac-4593-bbe4-3c8846e011b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n|   Account No|       Total_Balance|\n+-------------+--------------------+\n|409000438611'|-2.49486577068339...|\n|     1196711'|-1.60476498101275E13|\n|     1196428'| -8.1418498130721E13|\n|409000493210'|-3.27584952132095...|\n|409000611074'|       1.615533622E9|\n|409000425051'|-3.77211841164998...|\n|409000405747'|-2.43108047067000...|\n|409000493201'|1.0420831829499985E9|\n|409000438620'|-7.12291867951358...|\n|409000362497'| -5.2860004792808E13|\n+-------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "loans_df.createOrReplaceTempView(\"transactions\")\n",
    "\n",
    "sum_balance_per_account_sql = spark.sql(\"\"\"\n",
    "    SELECT `Account No`, SUM(`BALANCE AMT`) AS Total_Balance\n",
    "    FROM transactions\n",
    "    GROUP BY `Account No`\n",
    "\"\"\")\n",
    "sum_balance_per_account_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903bd0e0-4d80-4ee9-aa59-72113136a987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n|VALUE DATE|Num_Transactions|\n+----------+----------------+\n| 23-Dec-16|             143|\n|  7-Feb-19|              98|\n| 21-Jul-15|              80|\n|  9-Sep-15|              91|\n| 17-Jan-15|              16|\n| 18-Nov-17|              53|\n| 21-Feb-18|              77|\n| 20-Mar-18|              71|\n| 19-Apr-18|              71|\n| 21-Jun-16|              97|\n| 17-Oct-17|             101|\n|  3-Jan-18|              70|\n|  8-Jun-18|             223|\n| 15-Dec-18|              62|\n|  8-Aug-16|              97|\n| 17-Dec-16|              74|\n|  3-Sep-15|              83|\n| 21-Jan-16|              76|\n|  4-May-18|              92|\n|  7-Sep-17|              94|\n+----------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Count the number of transactions on each date\n",
    "transactions_per_date = loans_df.groupBy(\"VALUE DATE\").count()\n",
    "\n",
    "transactions_per_date = transactions_per_date.withColumnRenamed(\"count\", \"Num_Transactions\")\n",
    "\n",
    "transactions_per_date.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeeb9e27-75af-4e99-a0e1-ceef4382c68b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n|VALUE DATE|Num_Transactions|\n+----------+----------------+\n| 23-Dec-16|             143|\n|  7-Feb-19|              98|\n| 21-Jul-15|              80|\n|  9-Sep-15|              91|\n| 17-Jan-15|              16|\n| 18-Nov-17|              53|\n| 21-Feb-18|              77|\n| 20-Mar-18|              71|\n| 19-Apr-18|              71|\n| 21-Jun-16|              97|\n| 17-Oct-17|             101|\n|  3-Jan-18|              70|\n|  8-Jun-18|             223|\n| 15-Dec-18|              62|\n|  8-Aug-16|              97|\n| 17-Dec-16|              74|\n|  3-Sep-15|              83|\n| 21-Jan-16|              76|\n|  4-May-18|              92|\n|  7-Sep-17|              94|\n+----------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "loans_df.createOrReplaceTempView(\"transactions\")\n",
    "\n",
    "#query to count the number of transactions on each date\n",
    "transactions_per_date_sql = spark.sql(\"\"\"\n",
    "    SELECT `VALUE DATE`, COUNT(*) AS Num_Transactions\n",
    "    FROM transactions\n",
    "    GROUP BY `VALUE DATE`\n",
    "\"\"\")\n",
    "transactions_per_date_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dd03278-ae31-4dea-81cd-c4e850179e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n|   Account No| WITHDRAWAL AMT |\n+-------------+----------------+\n|409000611074'|          133900|\n|409000611074'|          195800|\n|409000611074'|          143800|\n|409000611074'|          331650|\n|409000611074'|          129000|\n|409000611074'|          230013|\n|409000611074'|          367900|\n|409000611074'|          108000|\n|409000611074'|          141000|\n|409000611074'|          206000|\n|409000611074'|          242300|\n|409000611074'|          113250|\n|409000611074'|          206900|\n|409000611074'|          276000|\n|409000611074'|          171000|\n|409000611074'|          189800|\n|409000611074'|          271323|\n|409000611074'|          200600|\n|409000611074'|          176900|\n|409000611074'|          150050|\n+-------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Filter customers with withdrawal amount greater than 1 lakh (100,000)\n",
    "customers_with_high_withdrawal = loans_df.filter(loans_df[\" WITHDRAWAL AMT \"] > 100000)\n",
    "\n",
    "# Select the relevant columns (Account No and WITHDRAWAL AMT)\n",
    "customers_with_high_withdrawal = customers_with_high_withdrawal.select(\"Account No\", \" WITHDRAWAL AMT \")\n",
    "\n",
    "customers_with_high_withdrawal.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b39834-6788-46fb-8ea7-741289a7f63f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n|   Account No| WITHDRAWAL AMT |\n+-------------+----------------+\n|409000611074'|          133900|\n|409000611074'|          195800|\n|409000611074'|          143800|\n|409000611074'|          331650|\n|409000611074'|          129000|\n|409000611074'|          230013|\n|409000611074'|          367900|\n|409000611074'|          108000|\n|409000611074'|          141000|\n|409000611074'|          206000|\n|409000611074'|          242300|\n|409000611074'|          113250|\n|409000611074'|          206900|\n|409000611074'|          276000|\n|409000611074'|          171000|\n|409000611074'|          189800|\n|409000611074'|          271323|\n|409000611074'|          200600|\n|409000611074'|          176900|\n|409000611074'|          150050|\n+-------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "loans_df.createOrReplaceTempView(\"transactions\")\n",
    "\n",
    "#query to get customers with withdrawal amount greater than 1 lakh\n",
    "customers_with_high_withdrawal_sql = spark.sql(\"\"\"\n",
    "    SELECT `Account No`, ` WITHDRAWAL AMT `\n",
    "    FROM transactions\n",
    "    WHERE ` WITHDRAWAL AMT ` > 100000\n",
    "\"\"\")\n",
    "customers_with_high_withdrawal_sql.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Tax",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
